{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6665c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.8.0-py2.py3-none-any.whl (272 kB)\n",
      "     -------------------------------------- 272.9/272.9 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting Twisted>=18.9.0\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 3.1/3.1 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\python 3.8\\lib\\site-packages (from scrapy) (21.3)\n",
      "Collecting cryptography>=3.4.6\n",
      "  Downloading cryptography-39.0.1-cp36-abi3-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting pyOpenSSL>=21.0.0\n",
      "  Downloading pyOpenSSL-23.0.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.3/57.3 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in c:\\python 3.8\\lib\\site-packages (from scrapy) (41.2.0)\n",
      "Collecting lxml>=4.3.0\n",
      "  Downloading lxml-4.9.2-cp38-cp38-win_amd64.whl (3.9 MB)\n",
      "     ---------------------------------------- 3.9/3.9 MB 4.0 MB/s eta 0:00:00\n",
      "Collecting zope.interface>=5.1.0\n",
      "  Downloading zope.interface-5.5.2-cp38-cp38-win_amd64.whl (211 kB)\n",
      "     -------------------------------------- 211.8/211.8 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting PyDispatcher>=2.0.5\n",
      "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
      "Collecting tldextract\n",
      "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.9/93.9 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting service-identity>=18.1.0\n",
      "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting parsel>=1.5.0\n",
      "  Downloading parsel-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\python 3.8\\lib\\site-packages (from cryptography>=3.4.6->scrapy) (1.15.0)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: six in c:\\python 3.8\\lib\\site-packages (from protego>=0.1.15->scrapy) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\python 3.8\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\python 3.8\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (21.4.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\python 3.8\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\python 3.8\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.4.0)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2\n",
      "  Downloading twisted_iocpsupport-1.0.2-cp38-cp38-win_amd64.whl (45 kB)\n",
      "     ---------------------------------------- 45.5/45.5 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.6/74.6 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python 3.8\\lib\\site-packages (from packaging->scrapy) (2.4.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\python 3.8\\lib\\site-packages (from tldextract->scrapy) (2.25.1)\n",
      "Requirement already satisfied: idna in c:\\python 3.8\\lib\\site-packages (from tldextract->scrapy) (2.10)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\python 3.8\\lib\\site-packages (from tldextract->scrapy) (3.0.12)\n",
      "Requirement already satisfied: pycparser in c:\\python 3.8\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python 3.8\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python 3.8\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python 3.8\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2020.12.5)\n",
      "Building wheels for collected packages: PyDispatcher\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=12991 sha256=a036d68d12ff746c277b4735d7ba95dea402ef2f5a1f5054d66c8095030d93ba\n",
      "  Stored in directory: c:\\users\\aashish\\appdata\\local\\pip\\cache\\wheels\\dc\\b9\\4a\\948b1176e084b9e3f85e4ffc3d08f817b1fdf0d973bbb94f81\n",
      "Successfully built PyDispatcher\n",
      "Installing collected packages: twisted-iocpsupport, PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, protego, lxml, jmespath, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, cryptography, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.6 Twisted-22.10.0 constantly-15.1.0 cryptography-39.0.1 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 lxml-4.9.2 parsel-1.7.0 protego-0.2.1 pyOpenSSL-23.0.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.8.0 service-identity-21.1.0 tldextract-3.4.0 twisted-iocpsupport-1.0.2 w3lib-2.1.1 zope.interface-5.5.2\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98775b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'firstScrapyProject', using template directory 'C:\\Python 3.8\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    D:\\ML\\ML_Practice\\firstScrapyProject\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd firstScrapyProject\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "#to create a scrapy project\n",
    "!scrapy startproject firstScrapyProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can refer to official docs of scrapy , it's easy one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
